# 该结果仅限于参考，并不是标准答案，具体问题应具体分析

# 关键字:
	学习率；动量；学习率调整策略；L2正则化；优化器
# Thingking
参考资料：吴恩达　Machine Learning Yearning

## 1.模型性能影响的因素
	1.模型的表达能力(深度和宽度)
	2.学习率
	3.优化器
	4.学习率调整策略
##2.模型过拟合的影响因素
	1.数据量(数据增强可以增加数据量)
	2.正则化
	模型的表达能力对模型是否过拟合的确会产生一定的影响，但选择合适的正则化可以有效的减缓这个影响，因此，不把模型的表达能力列入过拟合的因素．

## 讨论
###1. 学习率和动量
	问题：学习率过大或过小都会存在问题．
	1.学习率过大会导致模型无法进入局部最优甚至导致模型爆炸(不能收敛);
	2.学习率过小会导致模型训练速度慢，浪费时间．

经过四个实验：
	实验1:小学习率+小动量
	结论：模型训练速度慢，虽然收敛但收敛速度慢，验证集上性能稳定．
	
	实验2:小学习率+大动量
	结论：模型训练速度慢，虽然收敛但收敛速度慢，验证集上性能稳定．

	实验3:大学习率+小的动量
	结论：模型训练速度很快，很难收敛并且验证集上性能波动很大，说明了模型不稳定

	实验4:大学习率+大的动量
	结论:模型训练速度很快，收敛的也快，验证集上性能稳定.
	
	结合这四个实验得到以下结论：
	1.整合实验1与实验２.学习率小，模型稳定，但是也意味着模型朝正确的方向走的步长小.虽然有个很大的动量，但因为以前走的慢，动量很小，模型的移动速度并没有加快；
	2.学习率大，意味着模型不稳定，但是模型也是在朝着正确的方向上走；动量表示对过去学习的整合，动量大　->单次损失函数占比较低，相当于我这个模型的优化是由　本次的学习率+ 过去很多次学习率(弱机器学习)　计算出来的结果．

###2.学习率调整策略
	可以优先阐释以下三种：
	1.余弦退火：使用这个的时候，建议最大学习率和最小学习率不要差别太大(比如1e-1和1e-4), 不然会导致在该快的时候太慢，该慢的时候太快，特别是在接近最优解的时候，太大直接导致跑偏．推荐在warm-up时候使用．
	2.ReduceLROnPlateau:作者感觉这是这三个里面最好的，可以根绝训练的情况动态调整．使用这个的时候，最下学习率的设置需要注意，不然后期会因为后期因为学习率衰减的过小导致模型训练不到．
	3.StepLR很传统，但灵活度不如ReduceLROnPlateau.
###3.L2正则
	1.L2千万不要调太大，不然特别难训练；
	2.L2也不能太小，不然过拟合得挺严重的，大概1e-2也可以有不错的效果(resnet18)
	3.即使使用正确的正则化强度，也会导致前期不稳定甚至呈现训练不到的现象，但是之后就会稳定下来．

	




